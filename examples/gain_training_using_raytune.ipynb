{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GAIN trainining using Raytune\n",
    "* [Raytune](https://ray.io/)\n",
    "* [Raytune documentation](https://docs.ray.io/en/latest/tune/index.html)\n",
    "* [Raytune PyTorch turorial](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)\n",
    "## 1.1. Import all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from fireman_imputation.src import utils\n",
    "from fireman_imputation.gain_training import gain_train\n",
    "from fireman_imputation.src import gain_net\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gain_net.Generator(input_dim, input_dim)\n",
    "disc = gain_net.Discriminator(input_dim, input_dim)\n",
    "\n",
    "# if there is a checkpoint load the state, otherwise initialize the weights and optimizers\n",
    "if checkpoint_dir:\n",
    "    gen_state, gen_opt_state, \n",
    "    disc_state, disc_opt_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "    gen.load_state_dict(gen_model_state)\n",
    "    disc.load_state_dict(disc_model_state)\n",
    "    gen_opt.load_state_dict(gen_optimizer_state)\n",
    "    disc_opt.load_state_dict(disc_optimizer_state)\n",
    "else:\n",
    "    gen.apply(utils.init_weights)\n",
    "    disc.apply(utils.init_weights)\n",
    "    gen_opt = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    disc_opt = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "    gen.to(device)\n",
    "    disc.to(device)\n",
    "    # not tested https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html # noqa\n",
    "    # if torch.cuda.device_count() > 1:\n",
    "    #     gen = DistributedDataParallel(gen)\n",
    "    #     disc = DistributedDataParallel(disc)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    gen.to(device)\n",
    "    disc.to(device)\n",
    "    \n",
    "with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "    path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "    torch.save((gen.state_dict(), gen_opt.state_dict(), \n",
    "                disc.state_dict(), disc_opt.state_dict()), path)\n",
    "\n",
    "tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and scale the data\n",
    "data_orig = pd.read_csv('data/spam.csv',index_col=False)\n",
    "data = data_orig.values\n",
    "\n",
    "# create missing data\n",
    "data_missing, mask = utils.mcar_gen(data, 0.5)\n",
    "# scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(data_missing)\n",
    "data_missing = scaler.transform(data_missing)\n",
    "\n",
    "# divide the data to train/test\n",
    "# by default shuffles data, if pandas is passed the index shows shuffle result\n",
    "data_missing_train, data_missing_test, data_train, data_test = train_test_split(data_missing, data, train_size=0.9)\n",
    "\n",
    "# set hyper-parameters\n",
    "gain_params = {'batch_size': 100,\n",
    "               'hint_rate': 0.9,\n",
    "               'alpha': 100,\n",
    "               'epochs': 10,\n",
    "               'learning_rate': 0.001}\n",
    "\n",
    "# train the net\n",
    "gen, disc = gain_train(gain_params, data_missing_train, cont=False)\n",
    "\n",
    "# transform test data to tensor and forward it through generator\n",
    "data_missing_test_torch, mask_test_torch = utils.gain_data_prep(data_missing_test)\n",
    "data_imputed_test = gen(data_missing_test_torch, mask_test_torch)\n",
    "data_imputed_test = data_imputed_test.detach().numpy()\n",
    "\n",
    "# merge the imputed data(zero out rest in imputed data) and data with missing values\n",
    "inv_mask_test = 1 - mask_test_torch.numpy()\n",
    "# data_missing_test contains nan values\n",
    "data_missing_test_0 = data_missing_test.copy()\n",
    "data_missing_test_0[np.isnan(data_missing_test_0)] = 0\n",
    "data_imputed_test = inv_mask_test*data_imputed_test + data_missing_test_0\n",
    "\n",
    "# rescale the imputed data\n",
    "data_imputed_test = scaler.inverse_transform(data_imputed_test)\n",
    "data_missing_test = scaler.inverse_transform(data_missing_test)\n",
    "\n",
    "# compute error\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "RMSE = mean_squared_error(data_test, data_imputed_test, squared=False)\n",
    "print('RMSE of test dataset is {}'.format(RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
